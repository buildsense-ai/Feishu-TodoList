from fastapi import FastAPI, HTTPException, BackgroundTasks, Request, File, UploadFile
from pydantic import BaseModel
from typing import Optional
import uvicorn
from datetime import datetime, timedelta
from feishu_message_fetcher import FeishuMessageFetcher
from ai_message_processor import AIProjectAnalyzer
from database_manager import get_database_manager, DatabaseManager
from feishu_user_id_mapper import get_user_name_by_feishu_id, replace_user_ids_in_text, get_all_team_members, get_real_team_members, is_real_team_member, normalize_team_member_name
import json
import os
import httpx
import mysql.connector
from mysql.connector import Error
import requests

app = FastAPI(
    title="é£ä¹¦æ¶ˆæ¯AIåˆ†æç³»ç»Ÿ",
    description="""
## ğŸš€ æ™ºèƒ½é¡¹ç›®ç®¡ç†åŠ©æ‰‹ v2.7.0 - ç®€åŒ–ç‰ˆ

### ğŸ¯ æ ¸å¿ƒåŠŸèƒ½
- **é£ä¹¦æ¶ˆæ¯æ™ºèƒ½è·å–**: è‡ªåŠ¨æ‹‰å–ç¾¤ç»„æ¶ˆæ¯ï¼ˆæ˜¨å¤©10:30åˆ°ä»Šå¤©10:30ï¼‰
- **ç”¨æˆ·IDæ˜ å°„**: è‡ªåŠ¨å°†sender_idæ˜ å°„ä¸ºçœŸå®å§“å
- **AIæ™ºèƒ½åˆ†æ**: åŸºäºOpenRouter Gemini 2.5ç”ŸæˆToDoList
- **æŒ‰äººå‘˜åˆ†ç»„ç®¡ç†**: è‡ªåŠ¨è¯†åˆ«5ä¸ªå›¢é˜Ÿæˆå‘˜ï¼Œä»»åŠ¡æ¸…æ™°åˆ†ç±»
- **æ•°æ®åº“æŒä¹…åŒ–**: MySQLå­˜å‚¨ToDoListåˆ†æç»“æœ

### ğŸ“‹ ToDoListæ ¼å¼
**ä¸‰å¤§ä»»åŠ¡åˆ†ç±»ï¼ŒæŒ‰äººå‘˜ç»†åˆ†ï¼š**
- **ToDo (å¾…åŠ)**: æ–°æåˆ°çš„è®¡åˆ’ã€ä¸‹ä¸€æ­¥è¡ŒåŠ¨
- **Done (å·²å®Œæˆ)**: æ˜ç¡®æåˆ°å®Œæˆçš„å·¥ä½œ
- **Issues (é—®é¢˜)**: æŠ€æœ¯éš¾é¢˜ã€é˜»å¡ç‚¹

### ğŸ‘¥ å›¢é˜Ÿæˆå‘˜
ç³»ç»Ÿä»…ä¸ºä»¥ä¸‹5ä¸ªçœŸå®å›¢é˜Ÿæˆå‘˜åˆ†é…ä»»åŠ¡ï¼š
- **Michael**: å‰ç«¯UI
- **å°é’Ÿ**: åç«¯æ•°æ®åº“  
- **å›½ä¼Ÿ**: çˆ¬è™«æ•°æ®
- **äº‘èµ·**: AIè¯­éŸ³
- **Gauz**: æ¶æ„æ€§èƒ½

### â° æ—¶é—´èŒƒå›´
æ¯æ—¥ToDoListåˆ†æå‰ä¸€å¤©10:30åˆ°ä»Šå¤©10:30çš„æ‰€æœ‰æ¶ˆæ¯ï¼Œè¦†ç›–å®Œæ•´çš„å·¥ä½œå‘¨æœŸã€‚

### ğŸ’¾ æ•°æ®åº“åŠŸèƒ½
- **ToDoListæ•°æ®åº“**: feishu_todolist - å­˜å‚¨ä»»åŠ¡åˆ†æç»“æœ
- **å†å²è®°å½•æŸ¥è¯¢**: å¯æŸ¥è¯¢å†å²ä»»ä½•ä¸€å¤©çš„ToDoList
- **å·¥ä½œè´Ÿè½½åˆ†æ**: æˆå‘˜å·¥ä½œé‡ç»Ÿè®¡å’Œè¶‹åŠ¿åˆ†æ

### ğŸ› ï¸ é…ç½®è¦æ±‚
- é£ä¹¦App ID/Secret  
- OpenRouter API Key (Gemini 2.5)
- MySQLæ•°æ®åº“è¿æ¥

### ğŸ“‹ ä½¿ç”¨æµç¨‹
1. é…ç½®é£ä¹¦åº”ç”¨ã€OpenRouterå¯†é’¥å’ŒMySQLæ•°æ®åº“
2. è°ƒç”¨ `/daily-todolist` APIç”Ÿæˆæ¯æ—¥ToDoList
3. ä½¿ç”¨ `/db/*` APIæŸ¥è¯¢å†å²æ•°æ®å’Œç»Ÿè®¡åˆ†æ

æŠ€æœ¯æ ˆ: FastAPI + Gemini 2.5 + é£ä¹¦API + MySQL
    """,
    version="2.7.0",
    contact={
        "name": "é£ä¹¦AIåˆ†æç³»ç»Ÿ", 
        "email": "support@feishu-ai.com"
    }
)

# é…ç½®ä¿¡æ¯
APP_ID = "cli_a778ea0d0278100e"
APP_SECRET = "9h4EoFmjeTPgR344VWKu8fDmnxW76Cru"
DEFAULT_CONTAINER_ID = "oc_58605a887f1e11e359ceec1782c2d12d"  # é»˜è®¤ç¾¤èŠID

# AIé…ç½® - OpenRouter API
OPENROUTER_API_KEY = "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"
OPENROUTER_API_URL = "https://openrouter.ai/api/v1/chat/completions"
AI_MODEL = "google/gemini-2.5-pro-preview"  # OpenRouterä¸­çš„Gemini 2.5æ¨¡å‹

# å‘åå…¼å®¹ï¼Œä¹Ÿæ”¯æŒä»ç¯å¢ƒå˜é‡è·å–
API_KEY = os.getenv("OPENROUTER_API_KEY", OPENROUTER_API_KEY)

# è¯·æ±‚æ¨¡å‹
class MessageRequest(BaseModel):
    container_id: str  # ç¾¤èŠID
    start_time: Optional[str] = None  # å¼€å§‹æ—¶é—´æˆ³ï¼ˆç§’ï¼‰
    end_time: Optional[str] = None    # ç»“æŸæ—¶é—´æˆ³ï¼ˆç§’ï¼‰
    download_files: bool = True       # æ˜¯å¦ä¸‹è½½æ–‡ä»¶
    download_path: str = "./downloads"  # ä¸‹è½½è·¯å¾„

class TimeRangeRequest(BaseModel):
    container_id: str
    days_ago: int = 0  # å‡ å¤©å‰ï¼Œ0è¡¨ç¤ºä»Šå¤©ï¼Œ1è¡¨ç¤ºæ˜¨å¤©
    download_files: bool = True
    download_path: str = "./downloads"

class AIProcessRequest(BaseModel):
    """AIå¤„ç†è¯·æ±‚"""
    container_id: str = DEFAULT_CONTAINER_ID
    start_time: str = None  # å¼€å§‹æ—¶é—´ï¼Œæ ¼å¼ï¼šYYYY-MM-DD HH:MM:SS
    end_time: str = None    # ç»“æŸæ—¶é—´
    download_files: bool = False  # æ˜¯å¦ä¸‹è½½æ–‡ä»¶
    download_path: str = "downloads"  # ä¸‹è½½è·¯å¾„
    use_ai: bool = True     # æ˜¯å¦ä½¿ç”¨AI
    ai_api_key: str = None  # è‡ªå®šä¹‰AI APIå¯†é’¥

# å­˜å‚¨ä»»åŠ¡çŠ¶æ€
task_status = {}

@app.get("/")
async def root():
    """æ ¹è·¯å¾„ï¼Œæ˜¾ç¤ºAPIä¿¡æ¯"""
    return {
        "message": "é£ä¹¦æ¶ˆæ¯è·å–&AIåˆ†æAPIæœåŠ¡",
        "version": "2.7.0",
        "ai_provider": "OpenRouter Gemini 2.5",
        "features": [
            "ğŸ“¥ è·å–é£ä¹¦ç¾¤èŠæ¶ˆæ¯",
            "ğŸ¤– OpenRouter Gemini 2.5æ™ºèƒ½é¡¹ç›®åˆ†æ",
            "ğŸ‘¥ æŒ‰å›¢é˜Ÿæˆå‘˜åˆ†ç»„ä»»åŠ¡",
            "ğŸ“Š TODO/DONE/ISSUESæ·±åº¦æå–",
            "â° æ¯æ—¥ToDoListå®šæ—¶ç”Ÿæˆï¼ˆå‰ä¸€å¤©10:30åˆ°ä»Šå¤©10:30ï¼‰",
            "ğŸ”„ æ”¯æŒwebhookäº‹ä»¶æ¥æ”¶"
        ],
        "endpoints": [
            "GET /health - å¥åº·æ£€æŸ¥",
            "POST /fetch-messages - è·å–æ¶ˆæ¯ï¼ˆå®Œæ•´å‚æ•°ï¼‰",
            "POST /fetch-today - è·å–ä»Šå¤©çš„æ¶ˆæ¯",
            "POST /fetch-yesterday - è·å–æ˜¨å¤©çš„æ¶ˆæ¯",
            "POST /fetch-async - å¼‚æ­¥è·å–æ¶ˆæ¯",
            "POST /ai-analyze - AIé¡¹ç›®åˆ†æï¼ˆæŒ‰äººå‘˜åˆ†ç»„ä»»åŠ¡ï¼‰",
            "POST /ai-analyze-today - AIåˆ†æä»Šå¤©çš„é¡¹ç›®è®¨è®º",
            "POST /daily-todolist - ç”Ÿæˆæ¯æ—¥ToDoListï¼ˆæ˜¨å¤©10:30åˆ°ä»Šå¤©10:30ï¼‰",
            "GET /task-status/{task_id} - æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€",
            "POST /webhook/event - æ¥æ”¶é£ä¹¦äº‹ä»¶å›è°ƒï¼ˆURLéªŒè¯ï¼‰",
            "GET /db/latest-todolist - ä»æ•°æ®åº“è·å–æœ€æ–°ToDoList",
            "GET /db/member-workload - è·å–æˆå‘˜å·¥ä½œè´Ÿè½½ç»Ÿè®¡",
            "GET /db/daily-summary - è·å–æŒ‡å®šæ—¥æœŸToDoListæ±‡æ€»",
            "GET /db/health - æ£€æŸ¥æ•°æ®åº“è¿æ¥å¥åº·çŠ¶æ€"
        ]
    }

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy", 
        "timestamp": datetime.now().isoformat(),
        "ai_available": bool(API_KEY),
        "ai_provider": "OpenRouter Gemini 2.5",
        "ai_model": AI_MODEL,
        "version": "2.7.0",
        "features": {
            "chat_messages": True,
            "ai_analysis": bool(API_KEY),
            "daily_todolist": True,
            "webhook_support": True,
            "database_storage": True,
            "workload_analytics": True
        }
    }

@app.post("/ai-analyze")
async def ai_analyze_project(request: AIProcessRequest):
    """
    AIåˆ†æé¡¹ç›®å¯¹è¯ï¼ŒæŒ‰äººå‘˜åˆ†ç»„æå–TODO/DONE/ISSUESä»»åŠ¡ (çº¯AIæ¨¡å¼)
    """
    try:
        print(f"ğŸ” å¼€å§‹é¡¹ç›®åˆ†æè¯·æ±‚: {request.container_id}")
        
        # 1. è·å–æ¶ˆæ¯
        fetcher = FeishuMessageFetcher(
            app_id=APP_ID,
            app_secret=APP_SECRET,
            download_path=request.download_path
        )
        
        messages_data = fetcher.get_all_messages(
            container_id=request.container_id,
            start_time=request.start_time,
            end_time=request.end_time,
            download_files=request.download_files
        )
        
        # 2. AIé¡¹ç›®åˆ†æ (ä»…ä½¿ç”¨AI)
        ai_api_key = request.ai_api_key or API_KEY
        if not ai_api_key:
            raise ValueError("éœ€è¦OpenRouter APIå¯†é’¥æ‰èƒ½è¿›è¡Œåˆ†æ")
            
        analyzer = AIProjectAnalyzer(
            api_key=ai_api_key,
            model=AI_MODEL
        )
        
        analysis_result = analyzer.analyze_project_context(messages_data)
        
        # 3. ä¿å­˜ç»“æœ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"project_analysis_{timestamp}.json"
        analyzer.save_analysis_result(analysis_result, output_file)
        
        return {
            "success": True,
            "message": "AIé¡¹ç›®åˆ†æå®Œæˆ",
            "data": analysis_result,
            "output_file": output_file,
            "processing_mode": "OpenRouter Gemini 2.5",
            "ai_model": AI_MODEL
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"AIé¡¹ç›®åˆ†æå¤±è´¥: {str(e)}")

@app.post("/ai-analyze-today")
async def ai_analyze_today_project(request: TimeRangeRequest):
    """
    AIåˆ†æä»Šå¤©çš„é¡¹ç›®å¯¹è¯
    """
    now = datetime.now()
    today_start = datetime.combine(now.date(), datetime.min.time())
    
    ai_request = AIProcessRequest(
        container_id=request.container_id,
        start_time=str(int(today_start.timestamp())),
        end_time=str(int(now.timestamp())),
        download_files=request.download_files,
        use_ai=True
    )
    
    return await ai_analyze_project(ai_request)

@app.post("/daily-todolist")
async def generate_daily_todolist(request: TimeRangeRequest):
    """
    ç”Ÿæˆä»Šæ—¥ToDoList - ç®€åŒ–ç‰ˆæœ¬ï¼šä»…åˆ†ææ˜¨å¤©10:30åˆ°ä»Šå¤©10:30çš„æ¶ˆæ¯
    """
    try:
        print(f"ğŸ“… å¼€å§‹ç”Ÿæˆä»Šæ—¥ToDoList: {request.container_id}")
        
        # è®¡ç®—æ—¶é—´èŒƒå›´ï¼šæ˜¨å¤©10:30åˆ°ä»Šå¤©10:30
        now = datetime.now()
        today_1030 = datetime.combine(now.date(), datetime.min.time()) + timedelta(hours=10, minutes=30)
        yesterday_1030 = today_1030 - timedelta(days=1)
        
        print(f"â° æ—¶é—´èŒƒå›´: {yesterday_1030.strftime('%Y-%m-%d %H:%M:%S')} åˆ° {today_1030.strftime('%Y-%m-%d %H:%M:%S')}")
        
        # 1. è·å–æ¶ˆæ¯
        fetcher = FeishuMessageFetcher(
            app_id=APP_ID,
            app_secret=APP_SECRET,
            download_path=request.download_path
        )
        
        messages_data = fetcher.get_all_messages(
            container_id=request.container_id,
            start_time=str(int(yesterday_1030.timestamp())),
            end_time=str(int(today_1030.timestamp())),
            download_files=False  # ä¸ä¸‹è½½æ–‡ä»¶ï¼Œä¸“æ³¨æ–‡æœ¬åˆ†æ
        )
        
        print(f"ğŸ“¥ è·å–åˆ° {messages_data.get('total_count', 0)} æ¡æ¶ˆæ¯")
        
        # 2. ç®€åŒ–AIåˆ†æï¼šåªå¤„ç†æ¶ˆæ¯ï¼Œä¸åŒ…å«ä¼šè®®è®°å½•
        analyzer = AIProjectAnalyzer(
            api_key=API_KEY,
            model=AI_MODEL
        )
        
        daily_todolist = await generate_simple_daily_todolist(
            analyzer, messages_data
        )
        
        # 3. ä¿å­˜ä»Šæ—¥ToDoListåˆ°æ–‡ä»¶
        today_date = now.strftime("%Y%m%d")
        output_file = f"daily_todolist_{today_date}.json"
        analyzer.save_analysis_result(daily_todolist, output_file)
        
        # 4. ä¿å­˜åˆ°æ•°æ®åº“
        database_saved = False
        try:
            db_manager = get_database_manager()
            analysis_id = db_manager.save_todolist_analysis(daily_todolist)
            print(f"ğŸ“Š ToDoListå·²ä¿å­˜åˆ°æ•°æ®åº“ï¼Œåˆ†æID: {analysis_id}")
            database_saved = True
        except Exception as db_error:
            print(f"âš ï¸ æ•°æ®åº“ä¿å­˜å¤±è´¥: {db_error}")
            # æ•°æ®åº“ä¿å­˜å¤±è´¥ä¸å½±å“APIè¿”å›ç»“æœ
        
        print(f"âœ… ä»Šæ—¥ToDoListç”Ÿæˆå®Œæˆ: {output_file}")
        
        return {
            "success": True,
            "message": "ä»Šæ—¥ToDoListç”Ÿæˆå®Œæˆ",
            "data": daily_todolist,
            "output_file": output_file,
            "time_range": {
                "start": yesterday_1030.strftime('%Y-%m-%d %H:%M:%S'),
                "end": today_1030.strftime('%Y-%m-%d %H:%M:%S')
            },
            "total_messages": messages_data.get('total_count', 0),
            "total_meetings": 0,  # ä¸å†ä½¿ç”¨ä¼šè®®è®°å½•
            "database_saved": database_saved
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆä»Šæ—¥ToDoListå¤±è´¥: {str(e)}")

async def generate_simple_daily_todolist(analyzer, messages_data):
    """ç”Ÿæˆç®€åŒ–ç‰ˆä»Šæ—¥ToDoListåˆ†æ - åªå¤„ç†æ¶ˆæ¯"""
    print("ğŸ”„ å¼€å§‹ç”Ÿæˆç®€åŒ–ç‰ˆä»Šæ—¥ToDoListåˆ†æ...")
    
    messages = messages_data.get("messages", [])
    
    if not messages:
        print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æ¶ˆæ¯ï¼Œè¿”å›ç©ºToDoList")
        return {
            "analysis_timestamp": datetime.now().isoformat(),
            "analysis_type": "daily_todolist",
            "model": analyzer.model,
            "daily_todolist": {
                "ToDo": {},
                "Done": {},
                "Issue": {}
            },
            "message_count": 0,
            "status": "success"
        }
    
    # æ„å»ºæ¶ˆæ¯æ‘˜è¦ï¼ˆåŒ…å«sender_idåˆ°äººåçš„æ˜ å°„ï¼‰
    message_summary = build_daily_message_summary(messages)
    
    # è°ƒç”¨AIè¿›è¡Œä»Šæ—¥ToDoListåˆ†æ
    prompt = f"""ä»ä»¥ä¸‹é£ä¹¦ç¾¤èŠæ¶ˆæ¯ä¸­æå–å·¥ä½œä»»åŠ¡ï¼Œåˆ†é…ç»™å›¢é˜Ÿæˆå‘˜ã€‚

å›¢é˜Ÿæˆå‘˜ï¼ˆä»…é™5äººï¼‰:
- Michael: å‰ç«¯UI
- å°é’Ÿ: åç«¯æ•°æ®åº“  
- å›½ä¼Ÿ: çˆ¬è™«æ•°æ®
- äº‘èµ·: AIè¯­éŸ³
- Gauz: æ¶æ„æ€§èƒ½

æ¶ˆæ¯å†…å®¹:
{message_summary}

è¾“å‡ºè¦æ±‚:
1. åªèƒ½ä¸ºä¸Šè¿°5ä¸ªäººåˆ†é…ä»»åŠ¡
2. æ ¹æ®ä»»åŠ¡ç±»å‹å’Œæ¶ˆæ¯å†…å®¹æ™ºèƒ½åˆ†é…
3. ä¸¥æ ¼æŒ‰JSONæ ¼å¼è¾“å‡º

{{
    "ToDo": {{"Michael": [], "å°é’Ÿ": [], "å›½ä¼Ÿ": [], "äº‘èµ·": [], "Gauz": [], "å›¢é˜Ÿ": []}},
    "Done": {{"Michael": [], "å°é’Ÿ": [], "å›½ä¼Ÿ": [], "äº‘èµ·": [], "Gauz": [], "å›¢é˜Ÿ": []}},
    "Issue": {{"Michael": [], "å°é’Ÿ": [], "å›½ä¼Ÿ": [], "äº‘èµ·": [], "Gauz": [], "å›¢é˜Ÿ": []}}
}}"""

    try:
        headers = {
            "Content-Type": "application/json; charset=utf-8",
            "Authorization": f"Bearer {analyzer.api_key}",
            "HTTP-Referer": "https://feishu-analyzer.com",
            "X-Title": "Feishu Daily ToDoList Generator"
        }
        
        payload = {
            "model": analyzer.model,
            "messages": [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸“ä¸šçš„é¡¹ç›®ä»»åŠ¡ç®¡ç†åŠ©æ‰‹ã€‚ä¸¥æ ¼è§„åˆ™ï¼šåªèƒ½ä¸ºMichaelã€å°é’Ÿã€å›½ä¼Ÿã€äº‘èµ·ã€Gauzè¿™5ä¸ªäººåˆ†é…ä»»åŠ¡ã€‚ç»å¯¹ä¸å…è®¸è¾“å‡ºå…¶ä»–ä»»ä½•äººåï¼Œå¿…é¡»å°†æ‰€æœ‰ä»»åŠ¡é‡æ–°åˆ†é…ç»™è¿™5ä¸ªçœŸå®å›¢é˜Ÿæˆå‘˜ã€‚"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": 0.1,
        }
        
        response = requests.post(analyzer.api_url, headers=headers, json=payload, timeout=120)
            
        if response.status_code == 200:
            result = response.json()
            ai_response = result['choices'][0]['message']['content']
            
            # è§£æJSONå“åº”
            try:
                import re
                json_match = re.search(r'```json\s*(\{.*?\})\s*```', ai_response, re.DOTALL)
                if json_match:
                    todolist_json = json.loads(json_match.group(1))
                else:
                    # å¦‚æœæ²¡æœ‰markdownæ ¼å¼ï¼Œå°è¯•ç›´æ¥è§£æ
                    todolist_json = json.loads(ai_response.strip())
            except Exception as parse_error:
                print(f"âš ï¸ è§£æJSONå¤±è´¥: {parse_error}")
                # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨ç©ºçš„é»˜è®¤ç»“æ„
                todolist_json = {
                    "ToDo": {},
                    "Done": {},
                    "Issue": {}
                }
            
            return {
                "analysis_timestamp": datetime.now().isoformat(),
                "analysis_type": "daily_todolist",
                "model": analyzer.model,
                "daily_todolist": todolist_json,
                "message_count": len(messages),
                "status": "success"
            }
        else:
            raise Exception(f"OpenRouter APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")
            
    except Exception as e:
        print(f"âŒ AIåˆ†æå¤±è´¥: {e}")
        return {
            "analysis_timestamp": datetime.now().isoformat(),
            "analysis_type": "daily_todolist",
            "model": analyzer.model,
            "daily_todolist": {
                "ToDo": {},
                "Done": {},
                "Issue": {}
            },
            "message_count": len(messages),
            "status": "error",
            "error": str(e)
        }

def filter_todolist_by_real_members(ai_response):
    """
    è¿‡æ»¤ToDoListï¼Œåªä¿ç•™çœŸå®å›¢é˜Ÿæˆå‘˜çš„ä»»åŠ¡
    
    Args:
        ai_response (str): AIç”Ÿæˆçš„åŸå§‹å“åº”
        
    Returns:
        str: è¿‡æ»¤åçš„å“åº”
    """
    try:
        # å°è¯•è§£æJSON
        import re
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', ai_response, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        else:
            # å¦‚æœæ²¡æœ‰markdownæ ¼å¼ï¼Œå°è¯•ç›´æ¥è§£æ
            json_str = ai_response.strip()
        
        import json
        todolist_data = json.loads(json_str)
        
        # è·å–çœŸå®å›¢é˜Ÿæˆå‘˜
        real_members = get_real_team_members()
        allowed_categories = real_members + ['å›¢é˜Ÿ', 'æŠ€æœ¯']  # å…è®¸çš„åˆ†ç±»
        
        # è¿‡æ»¤æ¯ä¸ªåˆ†ç±»
        filtered_data = {}
        for category in ['ToDo', 'Done', 'Issue']:
            if category in todolist_data:
                filtered_category = {}
                for person, tasks in todolist_data[category].items():
                    # æ ‡å‡†åŒ–äººå‘˜åç§°
                    normalized_name = normalize_team_member_name(person)
                    if normalized_name:
                        # ä½¿ç”¨æ ‡å‡†åŒ–çš„åç§°
                        if normalized_name in filtered_category:
                            filtered_category[normalized_name].extend(tasks)
                        else:
                            filtered_category[normalized_name] = tasks
                    elif person in ['å›¢é˜Ÿ', 'æŠ€æœ¯']:
                        # ä¿ç•™å›¢é˜Ÿå’ŒæŠ€æœ¯åˆ†ç±»
                        if person in filtered_category:
                            filtered_category[person].extend(tasks)
                        else:
                            filtered_category[person] = tasks
                    else:
                        print(f"âš ï¸ è¿‡æ»¤æ‰æ— æ•ˆäººå‘˜: {person}")
                
                filtered_data[category] = filtered_category
        
        # é‡æ–°ç”ŸæˆJSONå“åº”
        filtered_json = json.dumps(filtered_data, ensure_ascii=False, indent=2)
        filtered_response = f"```json\n{filtered_json}\n```"
        
        print(f"âœ… ToDoListè¿‡æ»¤å®Œæˆï¼Œåªä¿ç•™çœŸå®å›¢é˜Ÿæˆå‘˜: {', '.join(real_members)}")
        return filtered_response
        
    except Exception as e:
        print(f"âš ï¸ ToDoListè¿‡æ»¤å¤±è´¥: {e}")
        return ai_response  # è¿”å›åŸå§‹å“åº”

def build_daily_message_summary(messages):
    """æ„å»ºæ¯æ—¥æ¶ˆæ¯æ‘˜è¦"""
    if not messages:
        return "æ— æ¶ˆæ¯å†…å®¹"
    
    summary = f"### ä»Šæ—¥å·¥ä½œæ¶ˆæ¯æ±‡æ€» ({len(messages)}æ¡)\n\n"
    
    # æŒ‰æ—¶é—´æ’åºæ¶ˆæ¯
    sorted_messages = sorted(messages, key=lambda x: int(x.get('create_time', 0)))
    
    for i, msg in enumerate(sorted_messages):
        msg_type = msg.get('msg_type', '')
        sender_id = msg.get('sender', {}).get('id', 'unknown')
        
        # è·å–çœŸå®ç”¨æˆ·åï¼Œå¹¶ç»Ÿä¸€æ˜ å°„ä¸ºçœŸå®å›¢é˜Ÿæˆå‘˜
        sender_name = get_user_name_by_feishu_id(sender_id)
        
        # å°†å‘é€è€…ç»Ÿä¸€æ˜ å°„ä¸ºçœŸå®å›¢é˜Ÿæˆå‘˜
        if sender_name in ['é’Ÿæ‚¦å¿ƒ', 'å°é’Ÿé˜¿æœ±', 'å°æ˜']:
            sender_name = 'å°é’Ÿ'
        elif sender_name == 'ç‹å­å¥':
            sender_name = 'Michael'
        elif sender_name.startswith('ç”¨æˆ·'):
            sender_name = "å›¢é˜Ÿæˆå‘˜"
        elif sender_name not in ['Michael', 'å°é’Ÿ', 'å›½ä¼Ÿ', 'äº‘èµ·', 'Gauz']:
            sender_name = "å›¢é˜Ÿæˆå‘˜"
        
        try:
            timestamp = datetime.fromtimestamp(int(msg.get('create_time', 0)) / 1000).strftime("%m-%d %H:%M")
        except:
            timestamp = f"æ¶ˆæ¯{i+1}"
        
        if msg_type == 'text':
            text = msg.get('text', '')
            # å¤„ç†é£ä¹¦å¯Œæ–‡æœ¬æ ¼å¼
            if '<p>' in text:
                import re
                clean_text = re.sub(r'<[^>]+>', '', text)
                clean_text = clean_text.replace('&nbsp;', ' ').strip()
                text = clean_text
            
            # åœ¨æ¶ˆæ¯å†…å®¹ä¸­ä¹Ÿæ›¿æ¢æ‰€æœ‰äººåä¸ºçœŸå®å›¢é˜Ÿæˆå‘˜
            text = replace_user_ids_in_text(text)
            
            # è¿›ä¸€æ­¥æ›¿æ¢æ¶ˆæ¯å†…å®¹ä¸­çš„äººå
            name_mapping = {
                'é’Ÿæ‚¦å¿ƒ': 'å°é’Ÿ',
                'å°é’Ÿé˜¿æœ±': 'å°é’Ÿ', 
                'å°æ˜': 'å°é’Ÿ',
                'ç‹å­å¥': 'Michael',
                'å‰ç«¯å›¢é˜Ÿ': 'å›¢é˜Ÿ',
                'æŠ€æœ¯å›¢é˜Ÿ': 'å›¢é˜Ÿ',
                'å¼€å‘å›¢é˜Ÿ': 'å›¢é˜Ÿ'
            }
            
            for old_name, new_name in name_mapping.items():
                text = text.replace(old_name, new_name)
            
            # é™åˆ¶å•æ¡æ¶ˆæ¯é•¿åº¦ï¼Œé¿å…è¿‡é•¿
            if len(text) > 500:
                text = text[:500] + "..."
            
            summary += f"**[{timestamp}] {sender_name}**: {text}\n\n"
    
    return summary

# @app.post("/webhook/event")
# async def handle_event(request: Request, background_tasks: BackgroundTasks):
#     """
#     æ¥æ”¶é£ä¹¦äº‹ä»¶å›è°ƒ - æ”¯æŒURLéªŒè¯ï¼Œç®€åŒ–äº‹ä»¶å¤„ç†
#     """
#     try:
#         # è·å–è¯·æ±‚ä½“
#         req_body = await request.json()
#         print(f"æ”¶åˆ°é£ä¹¦äº‹ä»¶: {json.dumps(req_body, indent=2, ensure_ascii=False)}")
        
#         # å¤„ç†URLéªŒè¯è¯·æ±‚
#         if req_body.get("type") == "url_verification":
#             challenge = req_body.get("challenge", "")
#             print(f"ğŸ”— é£ä¹¦URLéªŒè¯è¯·æ±‚ï¼Œè¿”å›challenge: {challenge}")
#             return {"challenge": challenge}
        
#         # å¤„ç†æ­£å¸¸çš„äº‹ä»¶å›è°ƒ
#         req_event = req_body.get("event", {})
        
#         # æ£€æŸ¥æ˜¯å¦æ˜¯æ¶ˆæ¯äº‹ä»¶
#         if req_event.get("type") == "message":
#             message_content = req_event.get("message", {})
#             chat_id = message_content.get("chat_id")
#             message_type = message_content.get("message_type", "")
            
#             print(f"ğŸ“¨ æ”¶åˆ°ç¾¤èŠæ¶ˆæ¯äº‹ä»¶: {chat_id}")
            
#             # ç®€åŒ–å¤„ç†ï¼šåªè®°å½•äº‹ä»¶ï¼Œä¸è§¦å‘è‡ªåŠ¨åˆ†æ
#             # ç”¨æˆ·å¯ä»¥æ‰‹åŠ¨è°ƒç”¨ /daily-todolist API ç”ŸæˆToDoList
#             return {
#                 "success": True,
#                 "message": "æ¶ˆæ¯äº‹ä»¶å·²æ¥æ”¶",
#                 "container_id": chat_id,
#                 "note": "è¯·æ‰‹åŠ¨è°ƒç”¨ /daily-todolist API ç”Ÿæˆæ¯æ—¥ToDoList"
#             }
        
#         # å…¶ä»–äº‹ä»¶ç±»å‹
#         print(f"ğŸ“¨ æ”¶åˆ°å…¶ä»–ç±»å‹äº‹ä»¶: {req_event.get('type', 'unknown')}")
#         return {
#             "success": True,
#             "message": "äº‹ä»¶å·²æ¥æ”¶",
#             "event_type": req_event.get("type", "unknown")
#         }
        
#     except Exception as e:
#         print(f"âŒ å¤„ç†webhookäº‹ä»¶å¤±è´¥: {str(e)}")
#         return {
#             "success": False,
#             "error": str(e)
#         }

@app.post("/fetch-messages")
async def fetch_messages(request: MessageRequest):
    """
    è·å–ç¾¤èŠæ¶ˆæ¯ï¼ˆå®Œæ•´å‚æ•°ç‰ˆæœ¬ï¼‰
    """
    try:
        print(f"ğŸ“¥ å¼€å§‹è·å–æ¶ˆæ¯: {request.container_id}")
        
        fetcher = FeishuMessageFetcher(
            app_id=APP_ID,
            app_secret=APP_SECRET,
            download_path=request.download_path
        )
        
        messages_data = fetcher.get_all_messages(
            container_id=request.container_id,
            start_time=request.start_time,
            end_time=request.end_time,
            download_files=request.download_files
        )
        
        # ä¿å­˜æ¶ˆæ¯æ•°æ®
        output_file = fetcher.save_messages_to_json(messages_data)
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = _get_message_type_stats(messages_data.get("messages", []))
        total_files = _count_total_files(messages_data.get("messages", []))
        
        return {
            "success": True,
            "message": "æ¶ˆæ¯è·å–å®Œæˆ",
            "data": messages_data,
            "output_file": output_file,
            "statistics": {
                "total_messages": messages_data.get("total_count", 0),
                "message_types": stats,
                "total_files_downloaded": total_files,
                "time_range": messages_data.get("time_range", {})
            }
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–æ¶ˆæ¯å¤±è´¥: {str(e)}")

@app.post("/fetch-today")
async def fetch_today_messages(request: TimeRangeRequest):
    """
    è·å–ä»Šå¤©çš„æ¶ˆæ¯
    """
    now = datetime.now()
    today_start = datetime.combine(now.date(), datetime.min.time())
    
    message_request = MessageRequest(
        container_id=request.container_id,
        start_time=str(int(today_start.timestamp())),
        end_time=str(int(now.timestamp())),
        download_files=request.download_files,
        download_path=request.download_path
    )
    
    return await fetch_messages(message_request)

@app.post("/fetch-yesterday")
async def fetch_yesterday_messages(request: TimeRangeRequest):
    """
    è·å–æ˜¨å¤©çš„æ¶ˆæ¯
    """
    now = datetime.now()
    yesterday_start = datetime.combine((now - timedelta(days=1)).date(), datetime.min.time())
    yesterday_end = datetime.combine(now.date(), datetime.min.time())
    
    message_request = MessageRequest(
        container_id=request.container_id,
        start_time=str(int(yesterday_start.timestamp())),
        end_time=str(int(yesterday_end.timestamp())),
        download_files=request.download_files,
        download_path=request.download_path
    )
    
    return await fetch_messages(message_request)

@app.post("/fetch-async")
async def fetch_messages_async(request: MessageRequest, background_tasks: BackgroundTasks):
    """
    å¼‚æ­¥è·å–æ¶ˆæ¯ - ç«‹å³è¿”å›ä»»åŠ¡IDï¼Œåå°å¤„ç†
    """
    import uuid
    task_id = str(uuid.uuid4())
    
    # å­˜å‚¨ä»»åŠ¡çŠ¶æ€
    task_status[task_id] = {
        "status": "pending",
        "created_at": datetime.now().isoformat(),
        "container_id": request.container_id
    }
    
    # æ·»åŠ åå°ä»»åŠ¡
    background_tasks.add_task(_fetch_messages_background, task_id, request)
    
    return {
        "task_id": task_id,
        "status": "pending",
        "message": "ä»»åŠ¡å·²æäº¤ï¼Œè¯·ä½¿ç”¨task_idæŸ¥è¯¢è¿›åº¦"
    }

@app.get("/task-status/{task_id}")
async def get_task_status(task_id: str):
    """
    æŸ¥è¯¢å¼‚æ­¥ä»»åŠ¡çŠ¶æ€
    """
    if task_id not in task_status:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡IDä¸å­˜åœ¨")
    
    return task_status[task_id]

async def _fetch_messages_background(task_id: str, request: MessageRequest):
    """
    åå°æ¶ˆæ¯è·å–ä»»åŠ¡
    """
    try:
        # æ›´æ–°çŠ¶æ€ä¸ºè¿›è¡Œä¸­
        task_status[task_id]["status"] = "running"
        task_status[task_id]["started_at"] = datetime.now().isoformat()
        
        # æ‰§è¡Œè·å–ä»»åŠ¡
        fetcher = FeishuMessageFetcher(
            app_id=APP_ID,
            app_secret=APP_SECRET,
            download_path=request.download_path
        )
        
        messages_data = fetcher.get_all_messages(
            container_id=request.container_id,
            start_time=request.start_time,
            end_time=request.end_time,
            download_files=request.download_files
        )
        
        # ä¿å­˜æ¶ˆæ¯æ•°æ®
        output_file = fetcher.save_messages_to_json(messages_data)
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = _get_message_type_stats(messages_data.get("messages", []))
        total_files = _count_total_files(messages_data.get("messages", []))
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå®Œæˆ
        task_status[task_id].update({
            "status": "completed",
            "completed_at": datetime.now().isoformat(),
            "result": {
                "output_file": output_file,
                "total_messages": messages_data.get("total_count", 0),
                "message_types": stats,
                "total_files_downloaded": total_files
            }
        })
        
    except Exception as e:
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
        task_status[task_id].update({
            "status": "failed",
            "failed_at": datetime.now().isoformat(),
            "error": str(e)
        })

def _get_message_type_stats(messages):
    """ç»Ÿè®¡æ¶ˆæ¯ç±»å‹åˆ†å¸ƒ"""
    stats = {}
    for msg in messages:
        msg_type = msg.get("msg_type", "unknown")
        stats[msg_type] = stats.get(msg_type, 0) + 1
    return stats

def _count_total_files(messages):
    """ç»Ÿè®¡ä¸‹è½½çš„æ–‡ä»¶æ€»æ•°"""
    total = 0
    for msg in messages:
        total += len(msg.get("files", []))
    return total

# =============================================================================
# æ•°æ®åº“æŸ¥è¯¢API
# =============================================================================

@app.get("/db/latest-todolist")
async def get_latest_todolist_from_db(container_id: str = None):
    """
    ä»æ•°æ®åº“è·å–æœ€æ–°çš„ToDoList
    """
    try:
        db_manager = get_database_manager()
        todolist_data = db_manager.get_latest_todolist(container_id)
        
        if not todolist_data:
            return {
                "success": False,
                "message": "æœªæ‰¾åˆ°ToDoListæ•°æ®",
                "data": None
            }
        
        return {
            "success": True,
            "message": "è·å–æœ€æ–°ToDoListæˆåŠŸ",
            "data": todolist_data
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–ToDoListå¤±è´¥: {str(e)}")

@app.get("/db/member-workload")
async def get_member_workload_stats(days: int = 7):
    """
    è·å–æˆå‘˜å·¥ä½œè´Ÿè½½ç»Ÿè®¡ï¼ˆæœ€è¿‘Nå¤©ï¼‰
    """
    try:
        db_manager = get_database_manager()
        workload_stats = db_manager.get_member_workload_stats(days)
        
        return {
            "success": True,
            "message": f"è·å–æœ€è¿‘{days}å¤©å·¥ä½œè´Ÿè½½ç»Ÿè®¡æˆåŠŸ",
            "data": workload_stats,
            "summary": {
                "total_members": len(set(item['assignee'] for item in workload_stats)),
                "date_range": f"æœ€è¿‘{days}å¤©",
                "total_records": len(workload_stats)
            }
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–å·¥ä½œè´Ÿè½½ç»Ÿè®¡å¤±è´¥: {str(e)}")

@app.get("/db/daily-summary")
async def get_daily_summary_from_db(target_date: str = None):
    """
    è·å–æŒ‡å®šæ—¥æœŸçš„ToDoListæ±‡æ€»
    æ ¼å¼: YYYY-MM-DDï¼Œé»˜è®¤ä¸ºä»Šå¤©
    """
    try:
        from datetime import date
        
        # è§£ææ—¥æœŸ
        if target_date:
            target_date_obj = datetime.strptime(target_date, '%Y-%m-%d').date()
        else:
            target_date_obj = date.today()
        
        db_manager = get_database_manager()
        summary_data = db_manager.get_daily_summary(target_date_obj)
        
        return {
            "success": True,
            "message": f"è·å–{target_date_obj}çš„ToDoListæ±‡æ€»æˆåŠŸ",
            "data": summary_data,
            "target_date": target_date_obj.isoformat(),
            "total_categories": len(set(item['category'] for item in summary_data if item['category'])),
            "total_assignees": len(set(item['assignee'] for item in summary_data if item['assignee']))
        }
        
    except ValueError:
        raise HTTPException(status_code=400, detail="æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨YYYY-MM-DDæ ¼å¼")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–æ¯æ—¥æ±‡æ€»å¤±è´¥: {str(e)}")

@app.get("/db/health")
async def check_database_health():
    """
    æ£€æŸ¥æ•°æ®åº“è¿æ¥å¥åº·çŠ¶æ€
    """
    try:
        db_manager = get_database_manager()
        
        # ç®€å•æŸ¥è¯¢æµ‹è¯•è¿æ¥
        with db_manager.get_connection() as conn:
            with conn.cursor() as cursor:
                cursor.execute("SELECT COUNT(*) as total FROM todolist_analysis")
                result = cursor.fetchone()
                total_analysis = result[0] if result else 0
                
                cursor.execute("SELECT COUNT(*) as total FROM todolist_items")
                result = cursor.fetchone()
                total_items = result[0] if result else 0
        
        return {
            "status": "healthy",
            "database": db_manager.config['database'],
            "host": db_manager.config['host'],
            "statistics": {
                "total_analysis_records": total_analysis,
                "total_todo_items": total_items
            },
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

# =============================================================================
# ä¼šè®®è®°å½•å¤„ç†åŠŸèƒ½ - æ–°å¢
# =============================================================================

class MeetingProcessor:
    """ä¼šè®®è®°å½•å¤„ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–ä¼šè®®è®°å½•å¤„ç†å™¨"""
        # DeepSeek APIé…ç½®
        self.deepseek_url = 'https://api.deepseek.com/v1'
        self.deepseek_key = 'sk-d2513b4c4626409599a73ba64b2e9033'
        
        # MySQLé…ç½® - ä¼šè®®è®°å½•æ•°æ®åº“
        self.mysql_config = {
            'host': 'gz-cdb-e0aa423v.sql.tencentcdb.com',
            'port': 20236,
            'user': 'root',
            'password': 'Aa@114514',
            'database': 'meeting_summaries_db'
        }
        
        # åˆå§‹åŒ–é£ä¹¦æœºå™¨äººå‘é€å™¨
        try:
            from feishu_bot_sender import FeishuBotSender
            self.feishu_bot = FeishuBotSender(
                app_id=APP_ID,
                app_secret=APP_SECRET,
                container_id=DEFAULT_CONTAINER_ID
            )
        except Exception as e:
            print(f"âš ï¸ é£ä¹¦æœºå™¨äººåˆå§‹åŒ–å¤±è´¥: {e}")
            self.feishu_bot = None
    
    def get_mysql_connection(self):
        """è·å–MySQLæ•°æ®åº“è¿æ¥"""
        try:
            connection = mysql.connector.connect(**self.mysql_config)
            return connection
        except Error as e:
            raise Exception(f"MySQLè¿æ¥å¤±è´¥: {e}")
    
    def process_meeting_transcript(self, transcript_content: str) -> dict:
        """å¤„ç†ä¼šè®®è®°å½•ï¼Œä½¿ç”¨DeepSeek APIåˆ†æ"""
        
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¼šè®®æ‘˜è¦åˆ†æä¸“å®¶ã€‚è¯·ä»”ç»†åˆ†æä»¥ä¸‹ä¼šè®®è®°å½•ï¼Œç”Ÿæˆä¸€ä¸ªè¯¦ç»†ã€ç»“æ„åŒ–çš„ä¼šè®®æ‘˜è¦ã€‚

è¯·ä»¥JSONæ ¼å¼è¿”å›ä»¥ä¸‹ç»“æ„ï¼Œæ³¨æ„æ‘˜è¦è¦è¯¦ç»†ã€åˆ†æ®µè½å‘ˆç°ï¼Œé‡ç‚¹çªå‡ºå¾…åŠäº‹é¡¹ã€å·²å®Œæˆäº‹é¡¹å’Œé‡è¦é—®é¢˜ï¼š

{{
    "summary": "è¯¦ç»†çš„ä¼šè®®æ€»ç»“ï¼Œè¦æ±‚ï¼š1)ç¬¬ä¸€æ®µæ˜¯ä¼šè®®æ•´ä½“æ¦‚è¿°ï¼ŒåŒ…å«ä¸»è¦è®®é¢˜ã€å‚ä¸æƒ…å†µã€ä¼šè®®ç›®æ ‡å’Œæ€»ä½“è¿›å±•ï¼›2)ç¬¬äºŒæ®µè¯¦è¿°é‡ç‚¹è®¨è®ºå†…å®¹ï¼›3)ç¬¬ä¸‰æ®µè¯´æ˜ä¼šè®®æˆæœå’Œåç»­å®‰æ’ã€‚æ¯æ®µåº”å½“è¯¦ç»†ã€å…·ä½“ï¼Œä¸å°‘äº100å­—ã€‚",
    "participants": ["å‚ä¸è€…å§“ååˆ—è¡¨"],
    "keywords": ["å…³é”®è¯åˆ—è¡¨ï¼Œæå–5-8ä¸ªæœ€é‡è¦çš„å…³é”®è¯"],
    "todos": [{{"task": "å¾…åŠä»»åŠ¡æè¿°", "assignee": "è´Ÿè´£äºº", "deadline": "æˆªæ­¢æ—¶é—´/é¢„è®¡å®Œæˆæ—¶é—´", "priority": "high/medium/low", "details": "ä»»åŠ¡è¯¦ç»†è¯´æ˜å’Œè¦æ±‚"}}],
    "dones": [{{"achievement": "å·²å®Œæˆäº‹é¡¹æè¿°", "contributor": "è´¡çŒ®è€…", "impact": "å½±å“å’Œæ„ä¹‰", "details": "å®Œæˆæƒ…å†µçš„è¯¦ç»†è¯´æ˜"}}],
    "major_issues": [{{"issue": "é‡è¦é—®é¢˜æè¿°", "impact": "é—®é¢˜å½±å“", "urgency": "ç´§æ€¥ç¨‹åº¦", "proposed_solutions": ["å»ºè®®è§£å†³æ–¹æ¡ˆ"], "discussion_points": ["ç›¸å…³è®¨è®ºè¦ç‚¹"]}}],
    "key_decisions": [{{"decision": "å†³ç­–æè¿°", "context": "å†³ç­–èƒŒæ™¯", "impact": "é¢„æœŸå½±å“", "owner": "è´Ÿè´£äºº", "rationale": "å†³ç­–ç†ç”±"}}],
    "action_items": [{{"task": "è¡ŒåŠ¨é¡¹", "assignee": "æŒ‡æ´¾äºº", "priority": "high/medium/low", "status": "new", "context": "ä»»åŠ¡èƒŒæ™¯"}}],
    "next_steps": [{{"step": "ä¸‹ä¸€æ­¥è¡ŒåŠ¨", "timeline": "æ—¶é—´å®‰æ’", "dependencies": ["ä¾èµ–æ¡ä»¶"], "owner": "è´Ÿè´£äºº"}}],
    "technical_discussions": [{{"topic": "æŠ€æœ¯ä¸»é¢˜", "discussion": "è®¨è®ºå†…å®¹", "decisions": ["æŠ€æœ¯å†³ç­–"], "concerns": ["æŠ€æœ¯å…³æ³¨ç‚¹"], "follow_ups": ["åç»­æŠ€æœ¯å·¥ä½œ"]}}],
    "ai_related_topics": [{{"topic": "AIç›¸å…³ä¸»é¢˜", "discussion": "è®¨è®ºå†…å®¹", "tools_mentioned": ["æåŠçš„AIå·¥å…·"], "outcomes": ["è®¨è®ºç»“æœ"], "implications": ["å¯¹é¡¹ç›®çš„å½±å“"]}}],
    "meeting_highlights": {{
        "most_important_decision": "æœ€é‡è¦çš„å†³ç­–",
        "biggest_challenge": "æœ€å¤§çš„æŒ‘æˆ˜",
        "key_breakthrough": "é‡è¦çªç ´æˆ–è¿›å±•",
        "urgent_attention_needed": "éœ€è¦ç´§æ€¥å…³æ³¨çš„äº‹é¡¹"
    }},
    "meeting_type": "æ ¹æ®å†…å®¹åˆ¤æ–­ï¼šproject_review/planning/brainstorming/decision_making/status_update/technical_discussion",
    "priority_level": "1-5çš„ä¼˜å…ˆçº§è¯„åˆ†ï¼Œ5ä¸ºæœ€é«˜",
    "tags": ["ä¼šè®®æ ‡ç­¾ï¼Œå¦‚ï¼šç´§æ€¥ã€é‡è¦ã€ä¾‹è¡Œã€æŠ€æœ¯ã€å•†åŠ¡ç­‰"]
}}

åˆ†æè¦æ±‚ï¼š
1. æ‘˜è¦å¿…é¡»è¯¦ç»†å…·ä½“ï¼Œåˆ†3ä¸ªè‡ªç„¶æ®µï¼Œæ¯æ®µä¸å°‘äº100å­—
2. TODOsï¼ˆå¾…åŠäº‹é¡¹ï¼‰è¦æ˜ç¡®ä»»åŠ¡ã€è´£ä»»äººã€æ—¶é—´è¦æ±‚
3. DONEsï¼ˆå·²å®Œæˆäº‹é¡¹ï¼‰è¦è¯´æ˜æˆæœå’Œä»·å€¼
4. é‡è¦é—®é¢˜è¦è¯„ä¼°å½±å“å’Œç´§æ€¥ç¨‹åº¦
5. ç”¨ä¸­æ–‡è¡¨è¾¾ï¼Œè¯­è¨€æ­£å¼ä½†æ˜“æ‡‚
6. å…³æ³¨é¡¹ç›®è¿›å±•ã€æŠ€æœ¯éš¾ç‚¹ã€èµ„æºéœ€æ±‚ã€é£é™©æ§åˆ¶ç­‰å…³é”®è¦ç´ 

ä¼šè®®è®°å½•ï¼š
{transcript_content}
"""

        try:
            headers = {
                'Authorization': f'Bearer {self.deepseek_key}',
                'Content-Type': 'application/json'
            }
            
            data = {
                'model': 'deepseek-chat',
                'messages': [
                    {'role': 'system', 'content': 'ä½ æ˜¯ä¸€ä½èµ„æ·±çš„é¡¹ç›®ç®¡ç†ä¸“å®¶å’Œä¼šè®®åˆ†æå¸ˆï¼Œæ“…é•¿ä»ä¼šè®®è®°å½•ä¸­æå–å…³é”®ä¿¡æ¯ï¼Œç”Ÿæˆé«˜è´¨é‡çš„ä¼šè®®æ‘˜è¦ã€‚ä½ çš„åˆ†æè¦è¯¦ç»†ã€å‡†ç¡®ã€æœ‰æ´å¯ŸåŠ›ï¼Œèƒ½å¤Ÿçªå‡ºé‡ç‚¹å¹¶è¯†åˆ«æ½œåœ¨é—®é¢˜ã€‚'},
                    {'role': 'user', 'content': prompt}
                ],
                'temperature': 0.1,
                'max_tokens': 6000
            }
            
            response = requests.post(
                f'{self.deepseek_url}/chat/completions',
                headers=headers,
                json=data,
                timeout=120
            )
            
            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content']
                
                json_start = content.find('{')
                json_end = content.rfind('}') + 1
                
                if json_start != -1 and json_end > json_start:
                    json_content = content[json_start:json_end]
                    parsed_result = json.loads(json_content)
                    return parsed_result
            
            raise Exception(f"DeepSeek APIè°ƒç”¨å¤±è´¥: {response.status_code}")
            
        except Exception as e:
            raise Exception(f"DeepSeekå¤„ç†å¤±è´¥: {e}")
    
    def save_meeting_summary(self, summary_data: dict, original_transcript: str = "") -> int:
        """ä¿å­˜ä¼šè®®æ‘˜è¦åˆ°æ•°æ®åº“"""
        try:
            connection = self.get_mysql_connection()
            
            # å‡†å¤‡æ‘˜è¦æ–‡æœ¬
            summary_text = summary_data.get('summary', '')
            
            # æ·»åŠ ç»“æ„åŒ–ä¿¡æ¯åˆ°æ‘˜è¦æ–‡æœ¬
            if summary_data.get('todos'):
                summary_text += "\n\nğŸ”¥ å¾…åŠäº‹é¡¹:\n"
                for i, todo in enumerate(summary_data['todos'], 1):
                    summary_text += f"{i}. {todo.get('task', '')} (è´Ÿè´£äºº: {todo.get('assignee', 'æœªæŒ‡å®š')}, æˆªæ­¢: {todo.get('deadline', 'å¾…å®š')})\n"
            
            if summary_data.get('dones'):
                summary_text += "\n\nâœ… å·²å®Œæˆäº‹é¡¹:\n"
                for i, done in enumerate(summary_data['dones'], 1):
                    summary_text += f"{i}. {done.get('achievement', '')} (è´¡çŒ®è€…: {done.get('contributor', 'å›¢é˜Ÿ')})\n"
            
            if summary_data.get('major_issues'):
                summary_text += "\n\nâš ï¸ é‡è¦é—®é¢˜:\n"
                for i, issue in enumerate(summary_data['major_issues'], 1):
                    summary_text += f"{i}. {issue.get('issue', '')} (ç´§æ€¥ç¨‹åº¦: {issue.get('urgency', 'å¾…å®š')})\n"
            
            # æ’å…¥æ•°æ®åº“
            cursor = connection.cursor()
            
            insert_query = """
            INSERT INTO meeting_summaries 
            (meeting_transcript, meeting_summary, meeting_date, participants, meeting_type, ai_provider, processing_status) 
            VALUES (%s, %s, %s, %s, %s, %s, %s)
            """
            
            values = (
                original_transcript,
                summary_text,
                datetime.now().isoformat(),
                json.dumps(summary_data.get('participants', [])),
                summary_data.get('meeting_type', 'general'),
                'deepseek',
                'completed'
            )
            
            cursor.execute(insert_query, values)
            connection.commit()
            
            meeting_id = cursor.lastrowid
            
            cursor.close()
            connection.close()
            
            return meeting_id
            
        except Exception as e:
            raise Exception(f"ä¿å­˜ä¼šè®®æ‘˜è¦å¤±è´¥: {e}")
    
    def send_to_feishu_group(self, summary_data: dict) -> bool:
        """å‘é€ä¼šè®®æ‘˜è¦åˆ°é£ä¹¦ç¾¤"""
        if not self.feishu_bot:
            print("âš ï¸ é£ä¹¦æœºå™¨äººæœªåˆå§‹åŒ–")
            return False
        
        try:
            return self.feishu_bot.send_summary_to_group(summary_data)
        except Exception as e:
            print(f"âŒ å‘é€åˆ°é£ä¹¦å¤±è´¥: {e}")
            return False

# åˆå§‹åŒ–ä¼šè®®å¤„ç†å™¨
meeting_processor = MeetingProcessor()

# ä¼šè®®è®°å½•è¯·æ±‚æ¨¡å‹
class MeetingTranscriptRequest(BaseModel):
    transcript: str

class MeetingSummaryRequest(BaseModel):
    summary: dict
    transcript: str = ""

@app.post("/meeting/analyze")
async def analyze_meeting_transcript(request: MeetingTranscriptRequest):
    """
    åˆ†æä¼šè®®è®°å½• - ä½¿ç”¨DeepSeek AIç”Ÿæˆç»“æ„åŒ–æ‘˜è¦
    """
    try:
        print(f"ğŸ“ å¼€å§‹åˆ†æä¼šè®®è®°å½•ï¼Œé•¿åº¦: {len(request.transcript)}å­—ç¬¦")
        
        # ä½¿ç”¨DeepSeek AIåˆ†æä¼šè®®è®°å½•
        summary_data = meeting_processor.process_meeting_transcript(request.transcript)
        
        print(f"âœ… ä¼šè®®è®°å½•åˆ†æå®Œæˆ")
        
        return {
            "success": True,
            "message": "ä¼šè®®è®°å½•åˆ†æå®Œæˆ",
            "data": summary_data,
            "processing_info": {
                "ai_provider": "DeepSeek",
                "transcript_length": len(request.transcript),
                "analysis_timestamp": datetime.now().isoformat()
            }
        }
        
    except Exception as e:
        print(f"âŒ ä¼šè®®è®°å½•åˆ†æå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"ä¼šè®®è®°å½•åˆ†æå¤±è´¥: {str(e)}")

@app.post("/meeting/save")
async def save_meeting_summary(request: MeetingSummaryRequest):
    """
    ä¿å­˜ä¼šè®®æ‘˜è¦åˆ°æ•°æ®åº“
    """
    try:
        print("ğŸ’¾ å¼€å§‹ä¿å­˜ä¼šè®®æ‘˜è¦åˆ°æ•°æ®åº“...")
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        meeting_id = meeting_processor.save_meeting_summary(
            request.summary, 
            request.transcript
        )
        
        print(f"âœ… ä¼šè®®æ‘˜è¦å·²ä¿å­˜ï¼ŒID: {meeting_id}")
        
        return {
            "success": True,
            "message": "ä¼šè®®æ‘˜è¦ä¿å­˜æˆåŠŸ",
            "meeting_id": meeting_id,
            "database": "meeting_summaries_db"
        }
        
    except Exception as e:
        print(f"âŒ ä¿å­˜ä¼šè®®æ‘˜è¦å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"ä¿å­˜ä¼šè®®æ‘˜è¦å¤±è´¥: {str(e)}")

@app.post("/meeting/send-feishu")
async def send_meeting_to_feishu(request: dict):
    """
    å‘é€ä¼šè®®æ‘˜è¦åˆ°é£ä¹¦ç¾¤
    """
    try:
        print("ğŸ“¤ å¼€å§‹å‘é€ä¼šè®®æ‘˜è¦åˆ°é£ä¹¦ç¾¤...")
        
        summary_data = request.get('summary', {})
        
        # å‘é€åˆ°é£ä¹¦ç¾¤
        success = meeting_processor.send_to_feishu_group(summary_data)
        
        if success:
            print("âœ… ä¼šè®®æ‘˜è¦å·²å‘é€åˆ°é£ä¹¦ç¾¤")
            return {
                "success": True,
                "message": "ä¼šè®®æ‘˜è¦å·²å‘é€åˆ°é£ä¹¦ç¾¤",
                "container_id": DEFAULT_CONTAINER_ID
            }
        else:
            raise Exception("å‘é€åˆ°é£ä¹¦ç¾¤å¤±è´¥")
            
    except Exception as e:
        print(f"âŒ å‘é€åˆ°é£ä¹¦ç¾¤å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å‘é€åˆ°é£ä¹¦ç¾¤å¤±è´¥: {str(e)}")

@app.post("/meeting/process-complete")
async def process_meeting_complete(file: UploadFile = File(...)):
    """
    å®Œæ•´çš„ä¼šè®®è®°å½•å¤„ç†æµç¨‹ï¼šä¸Šä¼ æ–‡ä»¶ â†’ AIåˆ†æ â†’ ä¿å­˜æ•°æ®åº“ â†’ å‘é€é£ä¹¦ç¾¤
    """
    try:
        print(f"ğŸ”„ å¼€å§‹å®Œæ•´ä¼šè®®è®°å½•å¤„ç†æµç¨‹ï¼š{file.filename}")
        
        # 1. è¯»å–ä¸Šä¼ çš„æ–‡ä»¶
        content = await file.read()
        transcript_text = content.decode('utf-8')
        
        print(f"ğŸ“– æ–‡ä»¶è¯»å–å®Œæˆï¼Œå†…å®¹é•¿åº¦: {len(transcript_text)}å­—ç¬¦")
        
        # 2. AIåˆ†æä¼šè®®è®°å½•
        print("ğŸ¤– å¼€å§‹AIåˆ†æ...")
        summary_data = meeting_processor.process_meeting_transcript(transcript_text)
        
        # 3. ä¿å­˜åˆ°æ•°æ®åº“
        print("ğŸ’¾ ä¿å­˜åˆ°æ•°æ®åº“...")
        meeting_id = meeting_processor.save_meeting_summary(summary_data, transcript_text)
        
        # 4. å‘é€åˆ°é£ä¹¦ç¾¤
        print("ğŸ“¤ å‘é€åˆ°é£ä¹¦ç¾¤...")
        feishu_success = meeting_processor.send_to_feishu_group(summary_data)
        
        print(f"âœ… å®Œæ•´æµç¨‹å¤„ç†å®Œæˆï¼")
        
        return {
            "success": True,
            "message": "ä¼šè®®è®°å½•å¤„ç†å®Œæˆ",
            "processing_steps": {
                "1_file_upload": "âœ… å®Œæˆ",
                "2_ai_analysis": "âœ… å®Œæˆ", 
                "3_database_save": f"âœ… å®Œæˆ (ID: {meeting_id})",
                "4_feishu_send": "âœ… å®Œæˆ" if feishu_success else "âŒ å¤±è´¥"
            },
            "data": {
                "meeting_id": meeting_id,
                "summary": summary_data,
                "transcript_length": len(transcript_text),
                "feishu_sent": feishu_success
            },
            "next_steps": [
                "ä¼šè®®æ‘˜è¦å·²å‘é€åˆ°é£ä¹¦ç¾¤",
                "å¯ä»¥è°ƒç”¨ /daily-todolist ç”ŸæˆåŒ…å«ä¼šè®®å†…å®¹çš„ToDoList",
                "å›¢é˜Ÿæˆå‘˜å¯ä»¥åœ¨é£ä¹¦ç¾¤ä¸­çœ‹åˆ°ä¼šè®®æ‘˜è¦"
            ]
        }
        
    except Exception as e:
        print(f"âŒ å®Œæ•´æµç¨‹å¤„ç†å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"ä¼šè®®è®°å½•å¤„ç†å¤±è´¥: {str(e)}")

# =============================================================================
# ä¼šè®®è®°å½•å¤„ç†åŠŸèƒ½ç»“æŸ
# =============================================================================

if __name__ == "__main__":
    # å¯åŠ¨APIæœåŠ¡å™¨
    print("ğŸš€ å¯åŠ¨é£ä¹¦æ¶ˆæ¯è·å–&AIåˆ†æAPIæœåŠ¡...")
    print(f"ğŸ“Š APIæ–‡æ¡£åœ°å€: http://localhost:8000/docs")
    print(f"ğŸ”§ å¥åº·æ£€æŸ¥: http://localhost:8000/health")
    
    uvicorn.run(
        app, 
        host="0.0.0.0", 
        port=8000
    ) 